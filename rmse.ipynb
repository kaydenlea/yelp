{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9863759406874498\n",
      "Absolute differences in range <1: 101407\n",
      "Absolute differences in range 1~2: 33543\n",
      "Absolute differences in range 2~3: 6283\n",
      "Absolute differences in range 3~4: 807\n",
      "Absolute differences in range 4~5: 4\n",
      "Prediction mean: 3.749827267580163\n",
      "Prediction std: 0.548377027757119\n",
      "Answer mean: 3.750499845118414\n",
      "Answer std: 1.1221530754078377\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def read_ratings_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        ratings = [float(line.split(\",\")[2]) for line in f.readlines()[1:]]\n",
    "    return ratings\n",
    "\n",
    "def calculate_rmse(predicted, actual):\n",
    "    diff_squared = [(p - a)**2 for p, a in zip(predicted, actual)]\n",
    "    rmse = np.sqrt(sum(diff_squared) / len(predicted))\n",
    "    return rmse\n",
    "\n",
    "def bin_differences(predicted, actual):\n",
    "    diff = [abs(p - a) for p, a in zip(predicted, actual)]\n",
    "    bins = {\"<1\": 0, \"1~2\": 0, \"2~3\": 0, \"3~4\": 0, \"4~5\": 0}\n",
    "    \n",
    "    for d in diff:\n",
    "        if d < 1: bins[\"<1\"] += 1\n",
    "        elif 1 <= d < 2: bins[\"1~2\"] += 1\n",
    "        elif 2 <= d < 3: bins[\"2~3\"] += 1\n",
    "        elif 3 <= d < 4: bins[\"3~4\"] += 1\n",
    "        else: bins[\"4~5\"] += 1\n",
    "    \n",
    "    return bins\n",
    "\n",
    "def print_stats(ratings, label):\n",
    "    print(f\"{label} mean: {np.mean(ratings)}\")\n",
    "    print(f\"{label} std: {np.std(ratings)}\")\n",
    "\n",
    "def main():\n",
    "    predicted_ratings = read_ratings_from_file(\"output2_3.csv\")\n",
    "    actual_ratings = read_ratings_from_file(\"publicdata/yelp_val.csv\")\n",
    "\n",
    "    rmse = calculate_rmse(predicted_ratings, actual_ratings)\n",
    "    differences = bin_differences(predicted_ratings, actual_ratings)\n",
    "\n",
    "    print(\"RMSE:\", rmse)\n",
    "    for key, value in differences.items():\n",
    "        print(f\"Absolute differences in range {key}: {value}\")\n",
    "\n",
    "    print_stats(predicted_ratings, \"Prediction\")\n",
    "    print_stats(actual_ratings, \"Answer\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from xgboost import XGBRegressor\n",
    "import json\n",
    "\n",
    "class ItemBasedCF:\n",
    "    def __init__(self):\n",
    "        self.biz_to_ratings = {}\n",
    "        self.biz_to_users = {}\n",
    "        self.user_to_biz = {}\n",
    "        self.avg_biz_ratings = {}\n",
    "        self.avg_user_ratings = {}\n",
    "\n",
    "    def _load_data(self, context, train_file, test_file):\n",
    "        train_data = context.textFile(train_file+ '/yelp_train.csv').filter(lambda x: \"user_id\" not in x).map(lambda x: x.split(\",\"))\n",
    "        test_data = context.textFile(test_file).filter(lambda x: \"user_id\" not in x).map(lambda x: x.split(\",\")).map(lambda x: (x[1], x[0]))\n",
    "\n",
    "        self.biz_to_ratings = train_data.map(lambda x: (x[1], (x[0], float(x[2])))).groupByKey().mapValues(dict).collectAsMap()\n",
    "        self.biz_to_users = {biz: set(users.keys()) for biz, users in self.biz_to_ratings.items()}\n",
    "        self.user_to_biz = train_data.map(lambda x: (x[0], x[1])).groupByKey().mapValues(set).collectAsMap()\n",
    "\n",
    "        self.avg_biz_ratings = train_data.map(lambda x: (x[1], float(x[2]))).groupByKey().mapValues(lambda v: sum(v) / len(v)).collectAsMap()\n",
    "        self.avg_user_ratings = train_data.map(lambda x: (x[0], float(x[2]))).groupByKey().mapValues(lambda v: sum(v) / len(v)).collectAsMap()\n",
    "\n",
    "        return test_data\n",
    "\n",
    "    def _calculate_weights(self, target_bus, current_user):\n",
    "        if current_user not in self.user_to_biz or target_bus not in self.biz_to_users:\n",
    "            return 3.5\n",
    "\n",
    "        weight_list = []\n",
    "\n",
    "        # Decay factor for mutual users; the lower the count, the higher the decay\n",
    "        decay = lambda count: 0.5**count\n",
    "\n",
    "        for other_bus in self.user_to_biz[current_user]:\n",
    "            mutual_users = self.biz_to_users[target_bus].intersection(self.biz_to_users[other_bus])\n",
    "\n",
    "            if not mutual_users:\n",
    "                # Use squared difference\n",
    "                w_val = 1 - ((self.avg_biz_ratings[target_bus] - self.avg_biz_ratings[other_bus])**2) / 25\n",
    "            else:\n",
    "                # Use squared differences for mutual users' ratings\n",
    "                rate_diffs = [(self.biz_to_ratings[target_bus][u] - self.biz_to_ratings[other_bus][u])**2 for u in mutual_users]\n",
    "                w_val = 1 - sum(rate_diffs) / (25 * len(rate_diffs))\n",
    "                w_val *= decay(len(mutual_users))\n",
    "\n",
    "            weight_list.append((w_val, self.biz_to_ratings[other_bus].get(current_user, self.avg_user_ratings[current_user])))\n",
    "\n",
    "        # Taking top weights\n",
    "        top_weights = sorted(weight_list, key=lambda x: -x[0])[:15]\n",
    "\n",
    "        sum_product = sum([weight * rating for weight, rating in top_weights])\n",
    "        total_weights = sum([abs(weight) for weight, _ in top_weights])\n",
    "\n",
    "        return sum_product / total_weights if total_weights != 0 else 3.5\n",
    "\n",
    "    def generate_predictions(self, train_file, test_file):\n",
    "        with SparkContext(appName=\"ItemBasedCF\") as context:\n",
    "            context.setLogLevel('Error')\n",
    "            test_data = self._load_data(context, train_file, test_file)\n",
    "            return {(user, biz): self._calculate_weights(biz, user) for biz, user in test_data.collect()}\n",
    "\n",
    "class XGBRatingPredictor: \n",
    "    @staticmethod\n",
    "    def extract_features(data, review_attr, user_attr, business_attr):\n",
    "        feature_list, user_business_pairs = [], []\n",
    "\n",
    "        for user, business, *_ in data:\n",
    "            user_business_pairs.append((user, business))\n",
    "\n",
    "            review_features = list(review_attr.get(business, [None, None, None]))\n",
    "            user_features = list(user_attr.get(user, [None, None, None]))\n",
    "            business_features = list(business_attr.get(business, [None, None]))\n",
    "\n",
    "            combined_features = review_features + user_features + business_features\n",
    "            feature_list.append(combined_features)\n",
    "\n",
    "        return np.array(feature_list, dtype='float32'), user_business_pairs\n",
    "\n",
    "    @staticmethod\n",
    "    def train_model(features, labels):\n",
    "        xgb_model = XGBRegressor()\n",
    "        xgb_model.fit(features, labels)\n",
    "        return xgb_model\n",
    "    def predict(self, train_dir, test_dir):\n",
    "        context = SparkContext(appName=\"XGBRatingPredictor\")\n",
    "        context.setLogLevel('Error')\n",
    "        \n",
    "        # Loading data\n",
    "        train_data = context.textFile(train_dir + '/yelp_train.csv') \\\n",
    "            .filter(lambda row: \"user_id\" not in row) \\\n",
    "            .map(lambda row: row.split(\",\"))\n",
    "\n",
    "        review_data = context.textFile(train_dir + '/review_train.json') \\\n",
    "            .map(json.loads) \\\n",
    "            .map(lambda row: (row['business_id'], (float(row['useful']), float(row['funny']), float(row['cool'])))) \\\n",
    "            .groupByKey() \\\n",
    "            .mapValues(lambda x: tuple(np.mean(np.array(list(x)), axis=0))) \\\n",
    "            .collectAsMap()\n",
    "\n",
    "        user_data = context.textFile(train_dir + '/user.json') \\\n",
    "            .map(json.loads) \\\n",
    "            .map(lambda row: (row['user_id'], (float(row['average_stars']), float(row['review_count']), float(row['fans'])))) \\\n",
    "            .collectAsMap()\n",
    "\n",
    "        business_data = context.textFile(train_dir + '/business.json') \\\n",
    "            .map(json.loads) \\\n",
    "            .map(lambda row: (row['business_id'], (float(row['stars']), float(row['review_count'])))) \\\n",
    "            .collectAsMap()\n",
    "\n",
    "        # Extract features for training\n",
    "        train_features, train_labels = zip(*[(features, float(label)) for *features, label in train_data.collect()])\n",
    "        X_train, _ = self.extract_features(train_features, review_data, user_data, business_data)\n",
    "        Y_train = np.array(train_labels, dtype='float32')\n",
    "\n",
    "        # Extract features for testing\n",
    "        test_data = context.textFile(test_dir) \\\n",
    "            .filter(lambda row: \"user_id\" not in row) \\\n",
    "            .map(lambda row: row.split(\",\"))\n",
    "        X_test, user_business_pairs = self.extract_features(test_data.collect(), review_data, user_data, business_data)\n",
    "\n",
    "        \n",
    "        xgb_model = self.train_model(X_train, Y_train)\n",
    "        predictions = xgb_model.predict(X_test)\n",
    "        \n",
    "        return {(user, business): pred for (user, business), pred in zip(user_business_pairs, predictions)}\n",
    "\n",
    "class HybridRecommender:\n",
    "\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.item_based_recommender = ItemBasedCF()\n",
    "        self.xgb_recommender = XGBRatingPredictor()\n",
    "\n",
    "    def predict(self, train_file, test_file):\n",
    "        # Get predictions from both models\n",
    "        item_based_preds = self.item_based_recommender.generate_predictions(train_file, test_file)\n",
    "        xgb_preds = self.xgb_recommender.predict(train_file, test_file)\n",
    "\n",
    "        # Combine predictions using the equation\n",
    "        final_preds = {}\n",
    "        for user_biz, score_item in item_based_preds.items():\n",
    "            score_model = xgb_preds.get(user_biz, 3.5)\n",
    "            final_score = self.alpha * score_item + (1 - self.alpha) * score_model\n",
    "            final_preds[user_biz] = final_score\n",
    "\n",
    "        return final_preds\n",
    "\n",
    "    def save_predictions(self, predictions, output_file):\n",
    "        with open(output_file, 'w') as results_file:\n",
    "            results_file.write(\"user_id, business_id, prediction\\n\")\n",
    "            for (user, biz), pred in predictions.items():\n",
    "                results_file.write(f\"{user},{biz},{pred}\\n\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    start_time = time.time()\n",
    "\n",
    "    alpha = 0.2\n",
    "    # Adjust as needed\n",
    "    train_filepath, test_filepath, output_filepath = sys.argv[1], sys.argv[2], sys.argv[3]\n",
    "\n",
    "    recommender = HybridRecommender(alpha)\n",
    "    final_predictions = recommender.predict(train_filepath, test_filepath)\n",
    "    recommender.save_predictions(final_predictions, output_filepath)\n",
    "\n",
    "    print(\"Duration:\", time.time() - start_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0000\n",
      "Recall: 0.9829\n",
      "Full Credit!\n",
      "Runtime: 0.03 seconds\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import time\n",
    "\n",
    "def load_data(filepath):\n",
    "    with open(filepath, 'r') as file:\n",
    "        reader = csv.reader(file)\n",
    "        data = set(tuple(sorted(row)) for row in reader)\n",
    "    return data\n",
    "\n",
    "def compute_metrics(ground_truth, predictions):\n",
    "    true_positives = len(ground_truth.intersection(predictions))\n",
    "    false_positives = len(predictions - ground_truth)\n",
    "    false_negatives = len(ground_truth - predictions)\n",
    "    \n",
    "    precision = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "    return precision, recall\n",
    "\n",
    "def compute_partial_score(precision, recall):\n",
    "    return (precision / 0.99) * 0.4 + (recall / 0.97) * 0.4\n",
    "\n",
    "def main():\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Load data\n",
    "    ground_truth = load_data('publicdata/pure_jaccard_similarity.csv')\n",
    "    predictions = load_data('output.csv')\n",
    "    \n",
    "    # Compute metrics\n",
    "    precision, recall = compute_metrics(ground_truth, predictions)\n",
    "    print(f'Precision: {precision:.4f}')\n",
    "    print(f'Recall: {recall:.4f}')\n",
    "    \n",
    "    if precision < 0.99 or recall < 0.97:\n",
    "        score = compute_partial_score(precision, recall)\n",
    "        print(f'Partial Score: {score:.4f}')\n",
    "    else:\n",
    "        print('Full Credit!')\n",
    "    \n",
    "    end_time = time.time()\n",
    "    runtime = end_time - start_time\n",
    "    print(f'Runtime: {runtime:.2f} seconds')\n",
    "    \n",
    "    if runtime >= 100:\n",
    "        print('No points, runtime exceeded limit!')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
